{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42967b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import stanza\n",
    "\n",
    "from stanza.server import CoreNLPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce1833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run once to install CoreNLP\n",
    "stanza.install_corenlp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512a07fb",
   "metadata": {},
   "source": [
    "# 1 - Entity extraction\n",
    "\"Entities are represented as a triple containing: a head word <i>h</i>, a list <i>A</A> of attribute relations, and a list <i>T</i> of trigger relations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f145ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_article():\n",
    "    file = json.load(open('database_dump_drugs/0.json'))\n",
    "    return file[0]['article_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e15f901",
   "metadata": {},
   "source": [
    "## 1.1 Head word extraction\n",
    "The paper states that \"Head words are extracted from noun phrases.\"  \n",
    "Noun phrases are defined as: \"A word or group of words containing a noun and functioning in a sentence as subject, object, or prepositional object.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99d944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-05 18:38:50 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\s161158\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-2e15724b8064491b.props -preload -outputFormat serialized\n"
     ]
    }
   ],
   "source": [
    "article = sample_article()\n",
    "sent = article[:114]  # first sentence of the article\n",
    "\n",
    "with CoreNLPClient(properties='corenlp_server-2e15724b8064491b.props') as client:\n",
    "    pattern = 'NP'\n",
    "    matches = client.tregex(text=sent, pattern=pattern)\n",
    "\n",
    "noun_phrases = [sentence[match_id]['spanString'] for sentence in matches['sentences'] for match_id in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['An Ethiopian foreign national',\n 'eMzinoni',\n 'drugs at his tuck shop',\n 'drugs',\n 'his tuck shop',\n 'Friday, 6']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_phrases"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The authors only use single words as head words. In the case of the first sentence of the first article, the head word of 'An Ethiopian foreign national' is 'national'.\n",
    "Therefore, we will have to reduce the extracted noun phrases to single nouns."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-05 18:39:55 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2021-07-05 18:39:55 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "| depparse  | combined |\n",
      "========================\n",
      "\n",
      "2021-07-05 18:39:55 INFO: Use device: cpu\n",
      "2021-07-05 18:39:55 INFO: Loading: tokenize\n",
      "2021-07-05 18:39:55 INFO: Loading: pos\n",
      "2021-07-05 18:39:56 INFO: Loading: lemma\n",
      "2021-07-05 18:39:56 INFO: Loading: depparse\n",
      "2021-07-05 18:39:57 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# In order to find the head nouns, we need POS-tagging and dependency parsing:\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse')\n",
    "doc = nlp(sent)\n",
    "# extract all candidate head words according to the Stanza dependency parser:\n",
    "heads = set([sent.words[word.head-1].text for sent in doc.sentences for word in sent.words])\n",
    "# keep only the candidate head words that are nouns\n",
    "heads = [word.text for sent in doc.sentences for word in sent.words if \"NN\" in word.xpos and word.text in heads]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['national', 'eMzinoni', 'drugs', 'shop', 'Friday', 'October']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heads"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['An Ethiopian foreign national',\n 'eMzinoni',\n 'drugs at his tuck shop',\n 'drugs',\n 'his tuck shop',\n 'Friday, 6']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_phrases"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# finally, output the words that were in the noun phrases, as well as the candidate head word list\n",
    "for phrase in noun_phrases:\n",
    "    for head in heads:\n",
    "        if head in phrase:\n",
    "            # noun_phrases[noun_phrases.index(phrase)] = head\n",
    "# noun_phrases = set(noun_phrases)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Trigger extraction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1) get verbs\n",
    "\n",
    "# 2) get 'eventive' nouns from the two wordnet synsets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Drop head words that are not related to at least one trigger"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# some more code"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 Extract head word attributes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# some more code"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "529c65a099ec80885ec2eff43b42ddd85d3b5611c57bcaf738fb7ba7dbdb85b1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}