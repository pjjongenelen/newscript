{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from stanza.server import CoreNLPClient\n",
    "\n",
    "ROOT = 'C:\\\\Users\\\\timjo\\\\PycharmProjects\\\\newscript\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Assign documents to clusters, and make dummy subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "muc_data = pd.read_pickle(ROOT + \"processed_data/muc_annotation.pkl\")\n",
    "with open(ROOT + \"src/chambers11/matrices/event_cluster_dict.json\", 'r') as file:\n",
    "    event_cluster_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_cluster(ev_patterns: list, ec_dict: dict) -> int:\n",
    "    \"\"\"Given a list of event patterns, returns the most frequent cluster.\n",
    "    This is just for testing purposes. In the real use-case we would assign documents to clusters based on the results of 1_\n",
    "    \n",
    "    Parameters:\n",
    "    ev_patterns: nested list of event patterns\n",
    "    ec_dict: dictionary that maps event patterns to clusters\n",
    "\n",
    "    Returns: \n",
    "    main_cluster: cluster number to which most event patterns belong\n",
    "    \"\"\"\n",
    "    \n",
    "    # I don't want to migrate to another python version (>3.7), so statistics.mode doesn't work\n",
    "    cluster_list = [ec_dict[ep[0]] for ep in ev_patterns]\n",
    "    main_cluster = max(set(cluster_list), key = cluster_list.count)\n",
    "\n",
    "    return main_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign documents to clusters\n",
    "muc_data['cluster'] = muc_data.apply(lambda x: get_main_cluster(x['event_patterns'], event_cluster_dict), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a developing dummy dataset\n",
    "dev_df = muc_data[muc_data.cluster == 1][:10].copy().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy case\n",
    "The 10 documents that have been loaded reprsent a cluster extracted with the existing code.   \n",
    "Now we first extract the correct coreference information using the annotations, after which we can cluster with the cosine distance.\n",
    "\n",
    "**In pseudocode:**  \n",
    "\n",
    "*Annotate articles*  \n",
    "_ FOR each article:  \n",
    "____ annotate the CoreNLPClient  \n",
    "_ return annotations  \n",
    "\n",
    "*---Current progress---*  \n",
    "\n",
    "*Fill the coreference matrix*  \n",
    "_ FOR each article annotation:  \n",
    "____ find all corefering sets of entities (set is of size 1 if no coreference is found)  \n",
    "____ FOR each corefering set:    \n",
    "_______ FOR each set member:  \n",
    "__________ extract subject/object verbs as *verb:o or verb:s*    \n",
    "_______ FOR each subject/object i:  \n",
    "__________ FOR each other subject/object j:  \n",
    "_____________ coref_matrix[i,j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_documents(documents: list, props_loc: str) -> list:\n",
    "    \"\"\"Annotates documents with the CoreNLPClient\"\"\"\n",
    "    \n",
    "    # annotate\n",
    "    with CoreNLPClient(endpoint='http://localhost:8001', timeout=30000, memory='4G') as client:\n",
    "        annotations = [client.annotate(doc) for doc in documents]\n",
    "    \n",
    "    # remove pesky .props file\n",
    "    files = os.listdir(os.getcwd())\n",
    "    for item in files:\n",
    "        if item.endswith(\".props\"):\n",
    "            os.remove(os.path.join(os.getcwd(), item))\n",
    "    \n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 17:07:31 INFO: Writing properties to tmp file: corenlp_server-56ede1c2683941ce.props\n",
      "2022-01-06 17:07:31 INFO: Starting server with command: java -Xmx4G -cp C:\\Users\\timjo\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 8001 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-56ede1c2683941ce.props -preload -outputFormat serialized\n"
     ]
    }
   ],
   "source": [
    "annotations = annotate_documents(documents = dev_df['text'], props_loc = ROOT + \"res/corenlp_server.props\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coref_matrix(ann, coref_matrix):\n",
    "    \"\"\"Goes over all entities in the coreference chain of a document, and updates the coreference matrix accordingly\n",
    "\n",
    "    Parameters:\n",
    "    ann (CoreNLP_pb2.Document): Annotation resulting from a Stanza CoreNLPClient, at least containing coreference information\n",
    "    coref_matrix (np.ndarray):  Matrix where [i,:] contains the corefer vector for event pattern i, without the information from the current document in ann\n",
    "\n",
    "    Returns:\n",
    "    coref_matrix (np.ndarray): Updated with the corefering argument information from this document\n",
    "\n",
    "    \"\"\"\n",
    "    for chain in ann.corefChain:\n",
    "        # extract entities\n",
    "\n",
    "        # for ent in entities:\n",
    "            # extract event patterns relating to this entity\n",
    "            # update the coreference matrix\n",
    "\n",
    "        chain\n",
    "    return coref_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>np</th>\n",
       "      <th>dum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    np  dum\n",
       "0  0.0    1\n",
       "1  0.0    1\n",
       "2  0.0    1\n",
       "3  0.0    1\n",
       "4  0.0    1\n",
       "5  0.0    1\n",
       "6  0.0    1\n",
       "7  0.0    1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_matrix= np.zeros(8)\n",
    "dummy = [1] * 8\n",
    "pd.DataFrame({'np': coref_matrix, 'dum': dummy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Brigade , which is headquartered in San Miguel , added that the seizure was made yesterday morning .'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([t.value for t in ann.sentence[11].token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\n",
      "-\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "for t in ann.sentence[8].token[1:4]:\n",
    "    print(t.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chainID: 80\n",
       "mention {\n",
       "  mentionID: 70\n",
       "  mentionType: \"PROPER\"\n",
       "  number: \"SINGULAR\"\n",
       "  gender: \"UNKNOWN\"\n",
       "  animacy: \"INANIMATE\"\n",
       "  beginIndex: 1\n",
       "  endIndex: 4\n",
       "  headIndex: 1\n",
       "  sentenceIndex: 8\n",
       "  position: 1\n",
       "}\n",
       "mention {\n",
       "  mentionID: 80\n",
       "  mentionType: \"PROPER\"\n",
       "  number: \"SINGULAR\"\n",
       "  gender: \"UNKNOWN\"\n",
       "  animacy: \"INANIMATE\"\n",
       "  beginIndex: 1\n",
       "  endIndex: 4\n",
       "  headIndex: 1\n",
       "  sentenceIndex: 10\n",
       "  position: 1\n",
       "}\n",
       "representative: 0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.corefChain[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "529c65a099ec80885ec2eff43b42ddd85d3b5611c57bcaf738fb7ba7dbdb85b1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
